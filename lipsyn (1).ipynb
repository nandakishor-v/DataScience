{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oo_27SV1yfr",
        "outputId": "6fb644d9-43da-4c8f-a8cd-8159eb814345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.14.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python matplotlib imageio gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "ozOOWk-ZgWfo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from matplotlib import pyplot as plt\n",
        "import imageio\n",
        "import gdown\n",
        "import pdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIkFl-DHgbA9",
        "outputId": "d74cdb8b-abb1-4f05-a5b3-e9796fc6807a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "WnbY4XENgbSb"
      },
      "outputs": [],
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "try:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkD2DmuMgmQ-"
      },
      "source": [
        "In the above cell block, the memory growth allows TensorFlow to allocate only as much GPU memory as needed by the process, rather than allocating the entire GPU memory upfront. This can be beneficial for improving memory utilization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPkYS4yLjJoM"
      },
      "source": [
        "# 1. Build Data Loading Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxpVFm7zhhUO"
      },
      "outputs": [],
      "source": [
        "url = 'https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL'\n",
        "output = 'data.zip'\n",
        "gdown.download(url, output, quiet=False)\n",
        "gdown.extractall('data.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "YQNFzhoZgl8W"
      },
      "outputs": [],
      "source": [
        "def load_video(path:str) -> List[float]:\n",
        "\n",
        "    cap = cv2.VideoCapture(path)\n",
        "\n",
        "    frames = []\n",
        "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
        "        ret, frame = cap.read()\n",
        "        frame = tf.image.rgb_to_grayscale(frame)\n",
        "        if frame.shape != (288, 360, 1):\n",
        "          print(\"Error in Shape while RGB conversion\")\n",
        "        #assert frame.shape == (288, 360, 1), f\"Unexpected frame shape: {frame.shape}\"\n",
        "        frame = frame[190:236,80:220,:]\n",
        "        #print(\"Shape after crop:\", frame.shape)\n",
        "        if frame.shape != (46, 140, 1):\n",
        "          print(\"Error in Shape while crop\")\n",
        "        #assert frame.shape == (46, 140, 1), f\"Unexpected frame shape: {frame.shape}\"\n",
        "        frame = tf.cast(frame, tf.float32)\n",
        "        frames.append(frame)\n",
        "    cap.release()\n",
        "\n",
        "    frames = tf.stack(frames)\n",
        "    mean = tf.math.reduce_mean(frames)\n",
        "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
        "    if frames.shape != (75, 46, 140, 1):\n",
        "      raise ValueError(f\"Unexpected frame shape: {frames.shape}, expected {(75, 46, 140, 1)}\")\n",
        "    return tf.cast((frames - mean), tf.float32) / std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "3NmQboDWgwsA"
      },
      "outputs": [],
      "source": [
        "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "49G-wJOrBXPv"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr_PSNMhhA4H",
        "outputId": "86e61391-59ee-48a8-959c-b42487719428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vocabulary is: ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' '] (size =40)\n"
          ]
        }
      ],
      "source": [
        "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
        "num_to_char = tf.keras.layers.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
        "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4clhf7g7ifEW"
      },
      "source": [
        "This code sets up two StringLookup layers using TensorFlow's Keras API, which is commonly used for mapping characters (or tokens) to numerical indices and vice versa.  Refer to this: \"https://keras.io/examples/audio/ctc_asr/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "e-9unYWAhWlK"
      },
      "outputs": [],
      "source": [
        "def load_alignments(path:str) -> List[str]:\n",
        "    with open(path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    tokens = []\n",
        "    for line in lines:\n",
        "        line = line.split()\n",
        "        if line[2] != 'sil':\n",
        "            tokens = [*tokens,' ',line[2]]\n",
        "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62Pj43ADij9y"
      },
      "source": [
        "function reads alignments from a file, extracts tokens excluding silence tokens, splits each token into characters, converts each character to a numerical index, and returns the result as a list of strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "xO1pSzUAhZXF"
      },
      "outputs": [],
      "source": [
        "def load_data(path: str):\n",
        "    path = bytes.decode(path.numpy())\n",
        "    file_name = path.split(os.path.sep)[-1].split('.')[0]  # Assuming you're on Windows\n",
        "    video_path = os.path.join('data', 's1', f'{file_name}.mpg')\n",
        "    alignment_path = os.path.join('data', 'alignments', 's1', f'{file_name}.align')\n",
        "    frames = load_video(video_path)\n",
        "    alignments = load_alignments(alignment_path)\n",
        "\n",
        "    return frames, alignments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7NWAmoDilmq"
      },
      "source": [
        " the file paths are provided as input, and the function returns the corresponding video frames and alignment data. It assumes a specific directory structure where video files are located in the 'data/s1' directory and alignment files are located in the 'data/alignments/s1' directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "cdyroMMliU0n"
      },
      "outputs": [],
      "source": [
        "def mappable_function(path:str) ->List[str]:\n",
        "    result = tf.py_function(load_data, [path], (tf.float32, tf.int64))\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bxcyMoAiymL"
      },
      "source": [
        "Overall, this function wraps the load_data function using tf.py_function() to make it compatible with TensorFlow's graph execution. It's suitable for use with TensorFlow datasets when you need to process data files in a pipeline, such as loading video frames and alignments from paths specified in the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHAS2sL0jOeG"
      },
      "source": [
        "# 2. Create Data Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhqQaKnOjU1e"
      },
      "source": [
        "we need to build a data pipeline that will be used to train the Deep learning model Tensorflow will draw random samples from our data set to complete one training step. we also needed to look at the data to make sure our Transformations have worked successfully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "5hqqibK6iYBB"
      },
      "outputs": [],
      "source": [
        "data = tf.data.Dataset.list_files('./data/s1/*.mpg')\n",
        "data = data.shuffle(500, reshuffle_each_iteration=False)\n",
        "data = data.map(mappable_function)\n",
        "data = data.padded_batch(2, padded_shapes=([75,None,None,None],[40]))\n",
        "data = data.prefetch(tf.data.AUTOTUNE)\n",
        "train = data.take(450)\n",
        "test = data.skip(450)\n",
        "\n",
        "frames, alignments = data.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUHrPC8_pCTO"
      },
      "source": [
        "this code sets up a TensorFlow dataset pipeline for efficiently processing video data, including loading, shuffling, mapping preprocessing functions, batching, and prefetching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek0XNpUuntZs",
        "outputId": "a2c7cf6a-18e7-4aa9-ae7b-f25a23288dcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 75, None, None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 40), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "9o--oaA-Kpa2"
      },
      "outputs": [],
      "source": [
        "frames, alignments = data.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(200):\n",
        "  frames, alignments = data.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "gj2Gr-N0KFJf"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3FTHuWPaVOzg"
      },
      "outputs": [],
      "source": [
        "sample = data.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtP1YEpfVvjW"
      },
      "outputs": [],
      "source": [
        "val = sample.next(); val[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "l8bfzZ-9YJG3"
      },
      "outputs": [],
      "source": [
        "#imageio.mimsave('./animation.gif', val[0][0], fps=10) showing error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import imageio\n",
        "\n",
        "\n",
        "print(\"Data Range:\", np.min(val[0][0]), \"-\", np.max(val[0][0]))\n",
        "\n",
        "\n",
        "max_val = np.max(val[0][0])\n",
        "min_val = np.min(val[0][0])\n",
        "frames_normalized = (val[0][0] - min_val) / (max_val - min_val) * 255\n",
        "\n",
        "frames_uint8 = frames_normalized.astype(np.uint8)\n",
        "\n",
        "frames_rgb = np.repeat(frames_uint8, 3, axis=-1)\n",
        "\n",
        "imageio.mimsave('./animation.gif', frames_rgb, fps=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGj8vbTB2auJ",
        "outputId": "a24c86e7-cf58-40c7-aa32-6dc90eea270f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Range: -4.8980327 - 2.538399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "Xb46F1DIV15q",
        "outputId": "4c2919cc-3e20-41a0-9bd7-9f39037acd73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7b4a82ba49a0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 0:videos, 0: 1st video out of the batch,  0: return the first frame in the video\n",
        "plt.imshow(val[0][0][35])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE512FDDWaSL",
        "outputId": "122d15c6-636b-443f-faa1-63ea55c32a7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'place green with y nine soon'>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "tf.strings.reduce_join([num_to_char(word) for word in val[1][0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcoZ8EQoW-oE"
      },
      "source": [
        "# 3. Design the Deep Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ka0N4A2jWe4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1681cb23-48b5-4261-e5c6-002ac7097f34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75, 46, 140, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "data.as_numpy_iterator().next()[0][0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHqFLsoctueO"
      },
      "source": [
        "data.as_numpy_iterator().next()[0][0].shape gives you the shape of the first element in the first batch of your dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6pwzubbhXP9o"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv3D(128, 3, input_shape=(75,46,140,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(Conv3D(256, 3, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(Conv3D(75, 3, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX_O-Dn4t_9y"
      },
      "source": [
        "here we are defining a Convolutional Neural Network (CNN) followed by a Bidirectional Long Short-Term Memory (BiLSTM) network for some kind of sequential data processing task.\n",
        "this architecture is designed to process spatiotemporal data such as videos and predict sequences of characters, making it suitable for tasks like video captioning or sign language recognition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "fZE6HYy_XTT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0344176e-9e1f-49a2-c4f1-8194ace2b5be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 75, 46, 140, 128   3584      \n",
            "                             )                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 75, 46, 140, 128   0         \n",
            "                             )                                   \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3  (None, 75, 23, 70, 128)   0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 75, 23, 70, 256)   884992    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 75, 23, 70, 256)   0         \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPoolin  (None, 75, 11, 35, 256)   0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 75, 11, 35, 75)    518475    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 75, 11, 35, 75)    0         \n",
            "                                                                 \n",
            " max_pooling3d_2 (MaxPoolin  (None, 75, 5, 17, 75)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, 75, 6375)          0         \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 75, 256)           6660096   \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 75, 256)           0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 75, 256)           394240    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 75, 256)           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 75, 41)            10537     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8471924 (32.32 MB)\n",
            "Trainable params: 8471924 (32.32 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq--8bw-Xhw3",
        "outputId": "6d9e725c-510f-435e-c81b-02c98d5c8ddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step\n"
          ]
        }
      ],
      "source": [
        "yhat = model.predict(val[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNhPelZ9ZGxp",
        "outputId": "a3372cec-2409-4908-dd1c-fb6709ddebd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllv'>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "tf.strings.reduce_join([num_to_char(x) for x in tf.argmax(yhat[0],axis=1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZE-PWsfZPqn",
        "outputId": "abf7fbf0-09b4-45e7-bd5d-8446e113841d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllv'>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "tf.strings.reduce_join([num_to_char(tf.argmax(x)) for x in yhat[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAXsqkERZTrl",
        "outputId": "c56abcb0-a718-43b6-e070-98d8a4048965"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 75, 46, 140, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "model.input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eejlxMqUZYH8",
        "outputId": "cb28a682-972d-4f96-88d4-a8405a3b0346"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 75, 41)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "model.output_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSIQ92UUuXLS"
      },
      "source": [
        "# 4. Setup Training Options and Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "au2NKgf3ZcAf"
      },
      "outputs": [],
      "source": [
        "def scheduler(epoch, lr):\n",
        "    if epoch < 30:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * tf.math.exp(-0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mzpv6YvRwXBh"
      },
      "source": [
        "\n",
        "This function scheduler(epoch, lr) defines a learning rate scheduler that decreases the learning rate exponentially after a certain number of epochs. Here's how it works:\n",
        "\n",
        "The function takes two arguments: epoch (the current epoch number) and lr (the current learning rate).\n",
        "\n",
        "If the current epoch number (epoch) is less than 30, the function returns the current learning rate (lr) without any change.\n",
        "After 30 epochs (epoch >= 30), the function returns the current learning rate multiplied by tf.math.exp(-0.1), which exponentially decreases the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "jMLpOtYKuyR2"
      },
      "outputs": [],
      "source": [
        "def CTCLoss(y_true, y_pred):\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "R9PFZRbau0py"
      },
      "outputs": [],
      "source": [
        "class ProduceExample(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, dataset) -> None:\n",
        "        self.dataset = dataset.as_numpy_iterator()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
        "        data = self.dataset.next()\n",
        "        yhat = self.model.predict(data[0])\n",
        "        decoded = tf.keras.backend.ctc_decode(yhat, [75,75], greedy=False)[0][0].numpy()\n",
        "        for x in range(len(yhat)):\n",
        "            print('Original:', tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))\n",
        "            print('Prediction:', tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))\n",
        "            print('~'*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "p1hfvXaeu4Ka"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss=CTCLoss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "SWigMCUqu7wW"
      },
      "outputs": [],
      "source": [
        "checkpoint_callback = ModelCheckpoint(os.path.join('models','checkpoint'), monitor='loss', save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Jbl3bFMRu_y3"
      },
      "outputs": [],
      "source": [
        "schedule_callback = LearningRateScheduler(scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Q81wKnv3vCoG"
      },
      "outputs": [],
      "source": [
        "example_callback = ProduceExample(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "ndUO7gNtvGCZ",
        "outputId": "1761a945-335c-44ec-bbf3-244eea1e02b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            " 45/450 [==>...........................] - ETA: 6:23 - loss: 121.4261"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-3f54ab0eeaa9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedule_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1811\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1813\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1814\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1815\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mwrong\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m   \"\"\"\n\u001b[0;32m--> 631\u001b[0;31m   return nest_util.map_structure(\n\u001b[0m\u001b[1;32m    632\u001b[0m       \u001b[0mnest_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1064\u001b[0m   \"\"\"\n\u001b[1;32m   1065\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_core_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_data_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m   return _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1104\u001b[0m   return _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \"\"\"\n\u001b[1;32m    393\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.fit(train, validation_data=test, epochs=100, callbacks=[checkpoint_callback, schedule_callback, example_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSJ3h2HWzsWV"
      },
      "source": [
        "# 5. Make a Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKjagee0vM14"
      },
      "outputs": [],
      "source": [
        "url = 'https://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y'\n",
        "output = 'checkpoints.zip'\n",
        "gdown.download(url, output, quiet=False)\n",
        "gdown.extractall('checkpoints.zip', 'models')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFPN2rBvz1zs"
      },
      "outputs": [],
      "source": [
        "model.load_weights('models/checkpoint')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "il-Tzr0_z5P5"
      },
      "outputs": [],
      "source": [
        "test_data = test.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAXlFvihz8Sn"
      },
      "outputs": [],
      "source": [
        "sample = test_data.next()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IjuW0sfeAj4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lo1HVhzmAj2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsq4Y-C10CA_"
      },
      "outputs": [],
      "source": [
        "yhat = model.predict(sample[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zXJV8js0Fmd"
      },
      "outputs": [],
      "source": [
        "print('~'*100, 'REAL TEXT')\n",
        "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2UOQEJF0Njq"
      },
      "outputs": [],
      "source": [
        "decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75,75], greedy=True)[0][0].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMX3JN8p0QxI"
      },
      "outputs": [],
      "source": [
        "print('~'*100, 'PREDICTIONS')\n",
        "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}